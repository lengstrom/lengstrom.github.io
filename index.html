<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <title>Logan Engstrom</title>
    <style>
      img {
        max-width: 98%;
        padding-right: 2%;
        vertical-align: middle;
      }
      table { table-layout: fixed; }
      td {
        width: 50%;
      }

      body {
        max-width: 600px;
        padding: 10px;
        padding-top: 25px;
        padding-bottom: 40px;
        margin: 0 auto;
        font-family: "Palatino Linotype", "Book Antiqua", Palatino, Georgia, serif;
        background-color: #fdfdfd;
        line-height: 1.35;
      }

      h1 {
        margin-top: 0;
        line-height: 1;
      }

      h3 {
        margin-bottom: -1px;
      }

      li {
        margin: 7px 0;
      }

      a { color:#2200CC; }
      a:hover {
        background-color:#2200CC;
        color:white;
      }
    </style>
  </head>
  <body>
    <table>
      <tr>
        <td>
          <img alt='Photo of Logan Engstrom' src='imgs/logan_2.jpg'>
        </td>
        <td style='padding-left:5px;'>
          <h1>Logan Engstrom</h1>
          Email: <a href='mailto:engstrom@mit.edu'>engstrom@mit.edu</a> <br>
          Google Scholar: <a href='https://scholar.google.com/citations?user=IWPWNxkAAAAJ'>here</a> <br>
          CV/Resume: <a href='raw/LoganEngstromCV.pdf'>here</a> <br>
          GitHub: <a href='https://github.com/lengstrom/'>@lengstrom</a>
        </td>
      </tr>
    </table>

    <h3>About</h3>
    <p>
    I'm a third year PhD student at <a href='https://www.mit.edu'>MIT EECS</a> researching
    machine learning. I am advised by <a href='https://people.csail.mit.edu/madry/lab/'>Aleksander Mądry</a> and funded by a <a href="https://research.google/outreach/phd-fellowship/">Google PhD Fellowship</a>.
    I am most interested in robust/reliable machine learning and understanding
    ML foundations. I previously worked at <a href='https://www.twosigma.com/'>Two Sigma</a> (summer 2018), <a href='https://research.google.com/teams/brain/'>Google Brain</a> (summer 2017) and <a href='https://apple.com'>Apple</a> (summer 2016).
    </p>
    <p>
        I went to MIT for undergrad and grew up in beautiful <a href='https://en.wikipedia.org/wiki/Lincoln,_Massachusetts'>Lincoln, MA</a>. Outside of research I contribute to <a href='https://github.com/lengstrom'>open source</a> and play pickup soccer.
    </p>

    <p>
      <center>
    Index: [<a href = "#publications">publications</a>] [<a href="#preprints">preprints</a>] [<a href="#opensource">Open Source</a>]
      </center>
    </p>

    <h3 name="publications">Publications</h3>
    <!-- <link rel="import" href="bib/publications.html"> -->
    <p>
    <ol>
      <li>
        <p>
          Andrew Ilyas, Sam Park, Logan Engstrom, Guillaume LeClerc, Aleksander Madry. <a href="https://arxiv.org/abs/2202.00622">Datamodels: Predicting Predictions from Training Data</a>. <em>ICML 2022</em>.
        </p>
      </li>
        <li>
          <p>
            Hadi Salman, Andrew Ilyas, Logan Engstrom, Sai Vemprala, Aleksander Madry, Ashish Kapoor. <a href="https://arxiv.org/abs/2012.12235">Unadversarial Examples: Designing Objects for Robust Vision</a>. <em>NeurIPS 2021</em>.
          </p>
        </li>
        <li>
          <p>
            Kai Xiao, Logan Engstrom, Andrew Ilyas, and Aleksander Madry. <a href="https://arxiv.org/abs/2005.09619">Noise or signal: The role of image backgrounds in object recognition</a>. <em>ICLR 2021</em>.
          </p>
        </li>
        <li>
          <p>
            Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, Aleksander Madry. <a href="https://arxiv.org/abs/2007.08489">Do Adversarially Robust ImageNet Models Transfer Better?</a>. <em>NeurIPS 2020 <b>Oral Presentation</b></em>.
          </p>
        </li>
        <li>
          <p>
              Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Jacob Steinhardt, and Aleksander Mądry.
              <a href="https://arxiv.org/abs/2005.09619">Statistical Bias in Dataset Replication</a>. <em>ICML 2020</em>.
          </p>
        </li>
        <li>
            <p>
                Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Firdaus Janoos, Larry Rudolph, and Aleksander Mądry.
                <a href="https://openreview.net/forum?id=r1etN1rtPB">Implementation Matters in Deep RL: A Case Study on PPO and TRPO</a>. <em>ICLR 2020 <b>Oral Presentation</b></em>.
            </p>
        </li>
        <li>
            <p>
                Andrew Ilyas, Logan Engstrom, Shibani Santurkar, Dimitris Tsipras, Firdaus Janoos, Larry Rudolph, and Aleksander Mądry.
                <a href="https://openreview.net/forum?id=ryxdEkHtPS">A Closer Look at Deep Policy Gradients</a>. <em>ICLR 2020 <b>Oral Presentation</b></em>.
            </p>
        </li>
        <li>
            <p>
                Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan
                Engstrom, Brandon Tran, and Aleksander Madry. <a href="https://arxiv.org/abs/1905.02175">Adversarial examples are not bugs, they are features</a>. <em>NeurIPS 2019 <b>Spotlight Presentation</b></em>.
            </p>
        </li>
        <li>
            <p>
                Shibani Santurkar, Dimitris Tsipras, Brandon Tran, Andrew Ilyas, Logan Engstrom, and Aleksander Madry. <a href="http://gradientscience.org/robust-apps.pdf">Computer vision with a single (robust) classifier.</a>. <em>NeurIPS 2019</em>.
            </p>
        </li>
      <li>
          <p>
              Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Mądry.
              <a href="https://arxiv.org/abs/1805.12152">Robustness May Be at Odds with Accuracy</a>. <em>ICLR 2019</em>.
          </p>
      </li>
      <li>
          <p>
              Andrew Ilyas, Logan Engstrom, Ludwig Schmidt, and Aleksander Mądry.
              <a href="https://arxiv.org/abs/1807.07978">Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors</a>. <em>ICLR 2019</em>.
          </p>
      </li>
      <li>
      <p>
      Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Mądry.
      <a href="https://arxiv.org/abs/1712.02779">A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations</a>.
    <em>ICML 2019</em>.
      </p>
      </li>
      <li>
          <p>
              Logan Engstrom, Andrew Ilyas, and Anish Athalye.
              <a href="https://arxiv.org/abs/1807.10272">Evaluating and Understanding the Robustness of Adversarial Logit Pairing</a>. <em>NIPS 2018 Machine Learning and Computer Security Workshop</em>.
          </p>
      </li>
      <li>
          <p>
              Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin.
              <a href="https://arxiv.org/abs/1804.08598">Black-box Adversarial Attacks with Limited Queries and Information</a>.
              <em>ICML 2018</em>.
          </p>
      </li>
      <li>
          <p>
              Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok.
              <a href="https://arxiv.org/abs/1707.07397">Synthesizing Robust Adversarial Examples</a>.
              <em>ICML 2018, Demo at NeurIPS 2017 Machine Learning and Computer Security Workshop</em>.
          </p>
      </li>

      <li>
      <p>
      Daniel Kang, Richard Sherwood, Amira Barkal, Tatsunori Hashimoto, Logan
        Engstrom, and David Gifford.
      <a href = 'http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0187046'>DNase-capture Reveals Differential Transcription Factor Binding
      modalities</a>.
      <em>PloS one</em>, 2017.
      </p>
      </li>
    </ol>

    <h3 name="preprints">Preprints</h3>
    <ol>
      <li>
        Guillaume Leclerc, Hadi Salman, Andrew Ilyas, Sai Vemprala, Logan Engstrom, Vibhav Vineet, Kai Xiao, Pengchuan Zhang, Shibani Santurkar, Greg Yang, Ashish Kapoor, and Aleksander Madry. <a href="https://arxiv.org/abs/2106.03805">3db: A framework for debugging computer vision models</a>. 2021.
      </li>
      <li>
          <p>
              Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon Tran, and Aleksander Madry. <a href="https://arxiv.org/abs/1906.00945">Learning perceptually-aligned representations via adversarial robustness</a>. 2019.
          </p>
      </li>
   </ol>

    <h3 name="opensource">Open Source</h3>
    <ul>
      <li>
      <a href="https://github.com/lengstrom/fast-style-transfer">
        Fast Style Transfer</a>: TensorFlow CNN for fast style transfer
      </li>
      <li>
      <a href="https://github.com/bijection/sistine">
        Sistine</a>: Webcam-based touch screen for any laptop
      </li>
      <li>
      <a href="https://tenso.rs/">
        TensorFire</a>: accelerated neural networks in the browser using WebGL
      </li>
      <li>
        <a href="https://github.com/lengstrom/tensorguard">
          Tensorguard</a>: Runtime typechecking for machine learning
        </li>
      <li>
        <a href="https://github.com/lengstrom/gitlinks">
          gitlinks</a>: Go-links for GitHub pages
        </li>
      <li>
      <a href="https://github.com/Hextris/hextris">
        Hextris</a>: Fast paced HTML5 puzzle game played by more than 10 million people
      </li>
      <li>
      <a href="https://github.com/lengstrom/falcon">
        Falcon</a>: Chrome extension for full text history search
      </li>
    </ul>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-51272720-4', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>

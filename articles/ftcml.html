<html>
	<head>
		<title>Machine Learning in FTC</title>
		<link href='http://fonts.googleapis.com/css?family=PT+Sans:400,700,400italic' rel='stylesheet' type='text/css'>
		<link rel="stylesheet" type="text/css" href="/css/style.css">
		<link rel="stylesheet" href="/vendor/highlight/styles/color-brewer.css">
	</head>
	<body>
		<span class = 'author_top'>August 3, 2014 / By <a href = '/'>Logan Engstrom</a></span>
		<div class = 'title header'>Machine Learning in FTC</div>
		<p>
			<i>Note: This article assumes knowledge of both matrices and the FTC Robotics competition.</i>
		</p>
		<br>
		<div class = 'title subHeader firstSubHeader'>
			<a href = '#introduction'>#</a>
			<b>Introduction: The Problems</b>
		</div>
		<p>A key challenge in the FIRST Tech Challenge robotics competition is finding IR beacon positions. Finding IR beacon positions seems easy. Machine learning is complex. Why bother with machine learning to find IR beacons?</p>
		<br>
		<p>The typical approach to finding IR beacon positions in the First Tech Challenge robotics competition is to have the robot start from a set position, read a categorical IR value from a sensor indicating the net direction from which IR rays are being emanated from, and then decide where the IR beacon is based on that value.</p>
		<br>
		<p>The problem is that the traditional approach produces irregular and often inaccurate results. It’s highly subject to a variety of sources of error, including human error (in hardsetting the IR value corresponding to each bucket, in setting up the robot, in setting up the IR beacons) and variation in IR beacons (IR beacons behave differently at different battery levels), and has precision limitations due to IR beacons’ granularity.</p>
		<br>
		<p>What can we do to solve these issues? One method is to repeatedly take IR values, throw out outliers, and then average them somehow (whether with the mean, median, mode, or center value). This method of filtering and averaging produces more consistent results, but doesn’t change the general approach, which remains flawed. </p>
		<div class = 'title subHeader firstSubHeader'>
			<a href = '#Solution'>#</a>
			<b>Solution</b>
		</div>
		<p>Instead, we could use machine learning, a set of methods in which algorithms (largely based in statistics) learn patterns from data. Supervised learning is a specific technique in which sample datasets and used to predict values. So, essentially, we’re finding trends in the data between response variables (the predicted IR beacon positions), or labels in the machine learning world, and the input data we have (IR values). After we find the trends, we can predict IR beacon locations based only upon the IR values we receive.</p>
		<br>
		<p>To take a quick detour, the only sensor available for detecting the IR beacons is the <a href='https://www.hitechnic.com/cgi-bin/commerce.cgi?preadd=action&key=NSK1042'>NXT IRSeeker V2</a>. Generally, teams use the combined IR value that the IRSeeker returns - a directional band from which the most powerful IR signal comes from. The problem with this is how vague it is. Each band is a different width, and a value representing a band could represent a signal from any part of the band. Instead, we’ll use the raw photodiode values from the IRSeeker’s photodiode array as input (each IRSeeker has 4 photodiodes from which a composite value is built) - this way, we get the raw data rather than the post-processed composites. So, in our fictional robot, we’ll be using 2 IRSeekers, each with 4 photodiodes, leaving us 8 different inputs to predict labels (IR positions) from. </p>
		<br>
		<div class = 'title subHeader firstSubHeader'>
			<a href = '#ML'>#</a>
			<b>Basic Machine Learning Introduction</b>
		</div>
		<p>To find the trends, we’re going to use linear regression. At it’s base, linear regression attempts to find the relationship between a vector of outputs $y$ and a matrix of inputs $X$. Each row of the matrix corresponds with both a set of inputs (the photodiode values) and an output in the corresponding row of $y$ (the IR position). Each column of the matrix represents an input category - in our case, each photodiode reading. To find the relationship between the inputs and the outputs, we’ll be trying to find a vector of coefficients, $b$, that, when multiplied with $X$ in the form $b^TX$, forms a vector product $\hat{y}$ that is most similar to the true outputs in $y$. How do we define <i>most similar</i>? Well, in our case we’ll be using a loss function, which indicates the difference between the true outputs and $b^TX$ as a scalar. We’ll use a mean squared error loss function, which models loss as the function: $$MSE = \frac{1}{n} \sum\limits_{i=1}^n (\hat{y}_i - y_i)^2$$ Here, MSE is the mean squared error and n is the number of inputs. To find the optimal vector $b$, we’ll use an optimization algorithm, gradient descent, to find the minimum of the MSE function, where a set of coefficients gives the most accurate model of the relationship between the photodiodes and IR beacon locations.</p>
		<br>

		<div class = 'title subHeader firstSubHeader'>
			<a href = '#Implementation'>#</a>
			<b>Implementation</b>
		</div>
		<p>To collect the data I mounted 2 IRSeekers on fixed positions on a robot, and then collected data by continuously reading IR sensor data from them for 2 minutes for each IR position. While they read, I slowly moved around the IR beacon and the robot as well to simulate placement variability. Each row of data had readings from 8 photodiodes (4 from each IRSeeker), and the IR position. In addition, for every match that I ran with the robot (whether practice matches or in competition), I read the initial IR values, placed them with the IR position, and added that to my data as well. </p>
		<br>
		<p>To perform the actual machine learning, we’re going to use the machine learning tool <a href = 'http://hunch.net/~vw/'>Vowpal Wabbit</a> (VW), a tool out of Microsoft Research. Install it using the instructions <a href ='https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial'>here</a>. VW has its own input format that you have to transform the data into (each row has formatting for parsing out inputs and outputs). VW will perform gradient descent for us very quickly (and thus can find close to the optimum vector $b$), and has a multitude of parameters that we can tune to make our predictions more accurate. I’ve attached all the data that we’ll need for this article in a zip at the very beginning of the article.</p>
		<br>
		<p>Unzip the file into a separate folder. Once you’ve installed VW, you can learn from the data. Use this command to run gradient descent on the data (where vw is the path to your VW executable):</p>
		<br>
		<pre>
			<code class='bash'>
				vw --passes 100 -d reg.txt -f final_regressor.txt
			</code>
		</pre>
		<br>
		<p>This runs through the data with stochastic gradient descent with 50 passes (allows the algorithm to run longer to get a more definitive optimum), and outputs the regressor (which contains the coefficients that map to each input, all in all forming the optimal vector $b$) in the text file final_regressor.txt</p>
		<br>
		<p>VW uses hashes to make it run faster - that’s why final_regressor.txt looks a bit strange. To unscramble the hashes and get a human readable regressor, use the following command:</p>
		<br>
		<pre>
			<code class='bash'>
				vw --holdout_off -k -t -i final_regressor.txt --invert_hash hr_regressor.txt -d reg.txt
			</code>
		</pre>
		<br>
		<p>From here, you should have a readable file that contains the appropriate coefficients for predicting your IR Beacon positions. In your implementation code, just multiply the values that you receive from the regressor for the inputs that they map to, sum them, and then round to the nearest whole number - from this, you should be able to receive accurate IR Beacon positions. </p>
		<br>

		<div class = 'title subHeader firstSubHeader'>
			<a href = '#Conclusion'>#</a>
			<b>Conclusions</b>
		</div>
		<p>The advantages of this approach are clear. Rather than manual methods of determining IR positions from sensor data (from overly simplified and granular inputs, at that), statistics and math are employed to find quantitatively better results. This removes variability from the detection process - both in terms of human error (with variations in IR beacon and robot positions) and in terms of other, unforeseeable error (such as battery levels, as VW automatically normalizes your data while optimizing). </p>

		<p>However, there are still a few clear problems. The coefficients don't provide perfect results, and have a hard time dealing with large variations from the dataset you learned on. In the next article, we’ll discuss tuning, overfitting, and alternative machine learning methods, all of which should help to mitigate these problems.</p>

		<br>
		<p></p>
		<br>

		<script src="/vendor/highlight/highlight.pack.js"></script>
		<script src="/vendor/jquery.js"></script>
		<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		</script>
		<script type="text/javascript">
			$('pre').each(function(i,o) {
				o.removeChild(o.childNodes[0])
				o.removeChild(o.childNodes[1])
			});

			$('code').each(function(i,o) {
				var z = o.childNodes[0];
				z.nodeValue = z.nodeValue.substring(z.nodeValue.indexOf('\n'),z.nodeValue.lastIndexOf('\n'));
				while (z.nodeValue.indexOf('\n') === 0) {
					z.nodeValue = z.nodeValue.substr(1);
				}

				var lines = z.nodeValue.split('\n');
				var min_lines = 999;

				lines.forEach(function(o) {
					if (o.replace(/\t/g, '').replace(/\s+/g, '') != '') {
						var lNum = 0;
						while (o.indexOf('\t') == 0) {
							lNum += 1;
							o = o.substr(1);
						}

						if (min_lines > lNum) {
							min_lines = lNum;
						}
					}
				});
				var fin = '';
				lines = z.nodeValue.split('\n');
				lines.forEach(function(o) {
					o = o.substr(min_lines);
					fin += o + '\n';
				});

				o.innerHTML = fin.replace(/\t/g,'    ');
			});

			hljs.initHighlightingOnLoad();
		</script>
	</body>
</html>